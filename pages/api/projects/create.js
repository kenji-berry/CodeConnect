import { createPagesServerClient } from '@supabase/auth-helpers-nextjs';
import { IncomingForm } from 'formidable';
import fs from 'fs';
import axios from 'axios';
import FormData from 'form-data';

export const config = {
  api: { bodyParser: false }
};

function parseField(field) {
  if (Array.isArray(field)) return field[0];
  return field;
}

async function fetchAllFromGitHub(url, githubToken) {
  let results = [];
  let page = 1;
  let hasMore = true;
  while (hasMore) {
    const res = await axios.get(`${url}${url.includes('?') ? '&' : '?'}per_page=100&page=${page}`, {
      headers: { Authorization: `token ${githubToken}` }
    });
    results = results.concat(res.data);
    // If less than 100 returned, we're done
    hasMore = Array.isArray(res.data) && res.data.length === 100;
    page++;
  }
  return results;
}

export default async function handler(req, res) {
  console.log('ðŸ“¥ API: Project create/update request received', { method: req.method, url: req.url });
  try {
    if (req.method !== 'POST') {
      console.log('âŒ API: Method not allowed', { method: req.method });
      return res.status(405).json({ error: 'Method not allowed' });
    }

    // Parse FormData
    console.log('ðŸ”„ API: Starting form parsing');
    const form = new IncomingForm({
      keepExtensions: true,
      maxFileSize: 50 * 1024 * 1024,
      multiples: true
    });

    const data = await new Promise((resolve, reject) => {
      form.parse(req, (err, fields, files) => {
        if (err) {
          console.error('âŒ API: Form parsing error', err);
          reject(err);
        } else {
          console.log('âœ… API: Form parsed successfully', { 
            fieldsReceived: Object.keys(fields),
            filesReceived: Object.keys(files)
          });
          resolve({ fields, files });
        }
      });
    });

    // Check Supabase session
    console.log('ðŸ”„ API: Checking Supabase session');
    const supabase = createPagesServerClient({ req, res });
    const { data: { session } } = await supabase.auth.getSession();
    if (!session) {
      console.log('âŒ API: No Supabase session found');
      return res.status(401).json({ error: 'Unauthorized' });
    }
    console.log('âœ… API: Supabase session valid', { userId: session.user.id, email: session.user.email });

    // Check GitHub token
    console.log('ðŸ”„ API: Checking GitHub token');
    const githubToken = req.cookies.github_access_token;
    if (!githubToken) {
      console.log('âŒ API: No GitHub token found');
      return res.status(401).json({ error: 'GitHub authentication required' });
    }
    console.log('âœ… API: GitHub token found');

    // Parse all fields
    console.log('ðŸ”„ API: Parsing form fields');
    const project_id = parseField(data.fields.project_id); 
    const repoName = parseField(data.fields.repoName);
    const owner = parseField(data.fields.owner);
    const github_link = parseField(data.fields.github_link);
    const description_type = parseField(data.fields.description_type);
    const custom_description = parseField(data.fields.custom_description);
    const difficulty_level = parseField(data.fields.difficulty_level);
    const tags = JSON.parse(parseField(data.fields.tags) || '[]');
    const technologies = JSON.parse(parseField(data.fields.technologies) || '[]');
    const highlighted_technologies = JSON.parse(parseField(data.fields.highlighted_technologies) || '[]');
    const highlighted_tags = JSON.parse(parseField(data.fields.highlighted_tags) || '[]');
    const links = JSON.parse(parseField(data.fields.links) || '[]');
    const status = parseField(data.fields.status);
    const contribution_types = JSON.parse(parseField(data.fields.contribution_types) || '[]');
    const mentorship = parseField(data.fields.mentorship);
    const license = parseField(data.fields.license);
    const setup_time = parseField(data.fields.setup_time);

    let isUpdate = !!project_id;
    console.log('âœ… API: Fields parsed successfully', { 
      isUpdate,
      project_id,
      repoName,
      owner,
      github_link,
      description_type,
      difficulty_level,
      tagsCount: tags.length,
      techCount: technologies.length,
      status
    });

    // If description_type is "Use existing description", fetch from GitHub
    console.log('ðŸ”„ API: Processing description', { type: description_type });
    let finalDescription = custom_description;
    const descType = description_type;
    if (
      descType &&
      String(descType).toLowerCase().includes('existing') &&
      github_link
    ) {
      try {
        console.log('ðŸ”„ API: Fetching description from GitHub', { github_link });
        let repoOwner = owner;
        let repoNameValue = repoName;
        const match = github_link.match(/github\.com\/([^\/]+)\/([^\/]+)/);
        if (match) {
          repoOwner = match[1];
          repoNameValue = match[2];
        }
        console.log('ðŸ”„ API: GitHub repo info', { repoOwner, repoNameValue });
        
        const response = await fetch(`https://api.github.com/repos/${repoOwner}/${repoNameValue}`, {
          headers: {
            'Authorization': `token ${githubToken}`,
            'Accept': 'application/vnd.github.v3+json'
          }
        });
        
        console.log('ðŸ”„ API: GitHub API response status:', response.status);
        if (response.ok) {
          const repoData = await response.json();
          finalDescription = repoData.description || '';
          console.log('âœ… API: GitHub description fetched successfully', { 
            description: finalDescription ? (finalDescription.length > 50 ? finalDescription.substring(0, 50) + '...' : finalDescription) : '(empty)'
          });
        } else {
          console.log('âš ï¸ API: Failed to fetch GitHub description', { 
            status: response.status, 
            statusText: response.statusText 
          });
        }
      } catch (err) {
        console.error('âŒ API: Error fetching GitHub description', err);
        // fallback to custom_description if fetch fails
      }
    }

    const difficulty = difficulty_level ? parseInt(difficulty_level, 10) : null;
    const setupTime = setup_time ? parseInt(setup_time, 10) : null;

    let imageUrl = null;
    if (data.files && data.files.banner_image) {
      console.log('ðŸ”„ API: Processing banner image');
      const file = Array.isArray(data.files.banner_image)
        ? data.files.banner_image[0]
        : data.files.banner_image;

      if (file && file.filepath) {
        try {
          const fileExt = file.originalFilename.split('.').pop();
          const fileType = file.mimetype;
          console.log('ðŸ”„ API: Image details', { 
            originalFilename: file.originalFilename, 
            fileType, 
            fileExt,
            size: fs.statSync(file.filepath).size 
          });
          
          const buffer = fs.readFileSync(file.filepath);
          console.log('ðŸ”„ API: Image buffer loaded, starting moderation');

          // Sightengine moderation
          const formData = new FormData();
          formData.append('models', 'nudity-2.1,weapon,alcohol,recreational_drug,medical,offensive-2.0,scam,text-content,face-attributes,gore-2.0,text,qr-content,tobacco,violence,self-harm,money,gambling');
          formData.append('api_user', process.env.SIGHTENGINE_USER);
          formData.append('api_secret', process.env.SIGHTENGINE_SECRET);
          formData.append('media', buffer, {
            filename: file.originalFilename,
            contentType: fileType,
          });

          console.log('ðŸ”„ API: Sending image to Sightengine for moderation');
          const sightengineResponse = await axios.post(
            'https://api.sightengine.com/1.0/check.json',
            formData,
            { headers: formData.getHeaders() }
          );

          const result = sightengineResponse.data;
          console.log('âœ… API: Sightengine moderation result', { 
            nudity_safe: result.nudity?.safe, 
            weapon: result.weapon?.weapon,
            offensive_prob: result.offensive?.prob,
            gore_prob: result.gore?.prob
          });
          
          if (
            result.nudity?.safe === false ||
            result.weapon?.weapon === true ||
            result.alcohol?.alcohol === true ||
            result.gore?.prob > 0.5 ||
            result.offensive?.prob > 0.5 ||
            result.violence?.violence === true ||
            result.scam?.scam === true ||
            result.self_harm?.self_harm === true ||
            result.gambling?.gambling === true
          ) {
            console.log('âŒ API: Image failed moderation');
            return res.status(400).json({ error: "Image failed moderation: contains inappropriate or restricted content." });
          }
        } catch (error) {
          console.error('âŒ API: Image moderation failed', error);
          let errorMsg = "Image moderation failed.";
          if (error.response && error.response.data && error.response.data.error) {
            errorMsg = typeof error.response.data.error === "string"
              ? error.response.data.error
              : JSON.stringify(error.response.data.error);
          }
          return res.status(400).json({ error: errorMsg });
        }
      }
    }
    // Check if banner image is provided
    console.log('ðŸ”„ API: Validating image requirements', { isUpdate, hasImage: !!(data.files && data.files.banner_image) });
    if (!isUpdate && (!data.files || !data.files.banner_image)) {
      console.log('âŒ API: Missing banner image for new project');
      return res.status(400).json({ error: 'Project banner image is required' });
    }

    // For updates, check if there's an existing image
    if (isUpdate && (!data.files || !data.files.banner_image)) {
      console.log('ðŸ”„ API: No new image provided for update, checking if existing image exists');
      // Check if the project already has an image
      const { data: existingProject, error: existingProjectError } = await supabase
        .from('project')
        .select('image')
        .eq('id', project_id)
        .single();

      if (existingProjectError) {
        console.error('âŒ API: Error checking existing project', existingProjectError);
      }

      if (!existingProject || !existingProject.image) {
        console.log('âŒ API: No existing image found for project update');
        return res.status(400).json({ error: 'Project banner image is required' });
      }
      
      console.log('âœ… API: Existing image found, proceeding with update');
    }

    // --- CREATE or UPDATE LOGIC ---
    console.log(`ðŸ”„ API: ${isUpdate ? 'Updating' : 'Creating'} project`);
    let project;
    let projectError;

    if (isUpdate) {
      // UPDATE existing project
      console.log('ðŸ”„ API: Updating project in database', { project_id });
      const { data: updated, error: updateError } = await supabase
        .from('project')
        .update({
          repo_name: repoName || 'Untitled Project',
          repo_owner: owner || session.user.email,
          github_link: github_link || null,
          description_type: description_type || null,
          custom_description: finalDescription || null,
          difficulty_level: isNaN(difficulty) ? null : difficulty,
          links: links,
          status: status || null,
          user_id: session.user.id,
          repo_name_owner: `${repoName || 'Untitled Project'} by ${owner || session.user.email}`,
          mentorship: mentorship === "Yes",
          license: license || null,
          setup_time: isNaN(setupTime) ? null : setupTime,
          // image: will update below if needed
        })
        .eq('id', project_id)
        .select()
        .single();
      project = updated;
      projectError = updateError;
      
      if (updateError) {
        console.error('âŒ API: Project update error', updateError);
      } else {
        console.log('âœ… API: Project updated successfully', { project_id: project.id });
      }
    } else {
      // CREATE new project
      console.log('ðŸ”„ API: Creating new project in database');
      const { data: created, error: createError } = await supabase
        .from('project')
        .insert([{
          repo_name: repoName || 'Untitled Project',
          repo_owner: owner || session.user.email,
          github_link: github_link || null,
          description_type: description_type || null,
          custom_description: finalDescription || null,
          difficulty_level: isNaN(difficulty) ? null : difficulty,
          links: links,
          status: status || null,
          user_id: session.user.id,
          created_at: new Date().toISOString(),
          repo_name_owner: `${repoName || 'Untitled Project'} by ${owner || session.user.email}`,
          mentorship: mentorship === "Yes",
          license: license || null,
          setup_time: isNaN(setupTime) ? null : setupTime,
          image: null,
          webhook_active: false 
        }])
        .select()
        .single();
      project = created;
      projectError = createError;
      
      if (createError) {
        console.error('âŒ API: Project creation error', createError);
      } else {
        console.log('âœ… API: Project created successfully', { project_id: project.id });
      }
    }

    if (projectError) {
      return res.status(500).json({ error: projectError.message });
    }

    // --- IMAGE UPLOAD (for both create and update) ---
    if (data.files && data.files.banner_image) {
      console.log('ðŸ”„ API: Processing image upload');
      const file = Array.isArray(data.files.banner_image)
        ? data.files.banner_image[0]
        : data.files.banner_image;

      if (file && file.filepath) {
        try {
          const fileExt = file.originalFilename.split('.').pop();
          const fileType = file.mimetype;
          const buffer = fs.readFileSync(file.filepath);

          const filename = `${session.user.id}/project_banners/${project.id}.${fileExt}`;
          console.log('ðŸ”„ API: Uploading image to storage', { filename, fileType });

          const { data: uploadData, error: uploadError } = await supabase.storage
            .from('project-images')
            .upload(filename, buffer, {
              contentType: fileType,
              cacheControl: '3600',
              upsert: true
            });

          if (uploadError) {
            console.error('âŒ API: Image upload error:', uploadError);
          } else {
            console.log('âœ… API: Image uploaded successfully');
            const { data: { publicUrl } } = supabase.storage
              .from('project-images')
              .getPublicUrl(filename);

            imageUrl = publicUrl;
            console.log('ðŸ”„ API: Updating project with image URL', { imageUrl });
            
            const { error: imageUpdateError } = await supabase
              .from('project')
              .update({ image: imageUrl })
              .eq('id', project.id);
              
            if (imageUpdateError) {
              console.error('âŒ API: Error updating project with image URL', imageUpdateError);
            } else {
              console.log('âœ… API: Project updated with image URL');
            }
          }
        } catch (error) {
          console.error('âŒ API: File processing error:', error);
          // Better error handling - continue with the project creation
          // but log the error for debugging
        } finally {
          // Clean up the temporary file
          try {
            fs.unlinkSync(file.filepath);
            console.log('âœ… API: Temporary file cleaned up');
          } catch (cleanupError) {
            console.error('âŒ API: File cleanup error:', cleanupError);
          }
        }
      }
    }

    // --- TECHNOLOGIES & TAGS ---
    console.log('ðŸ”„ API: Processing technologies and tags');
    // Remove old project_technologies/project_tags if updating
    if (isUpdate) {
      console.log('ðŸ”„ API: Removing old technologies and tags associations');
      const { error: techDeleteError } = await supabase.from('project_technologies').delete().eq('project_id', project.id);
      const { error: tagDeleteError } = await supabase.from('project_tags').delete().eq('project_id', project.id);
      
      if (techDeleteError) console.error('âŒ API: Error deleting old technologies', techDeleteError);
      if (tagDeleteError) console.error('âŒ API: Error deleting old tags', tagDeleteError);
    }

    // Map technology names to IDs
    let technologyIds = [];
    if (technologies.length > 0) {
      console.log('ðŸ”„ API: Fetching technology IDs', { technologies });
      const { data: techRows, error: techFetchError } = await supabase
        .from('technologies')
        .select('id, name')
        .in('name', technologies);

      if (techFetchError) {
        console.error('âŒ API: Error fetching technologies', techFetchError);
        return res.status(500).json({ error: techFetchError.message });
      }

      console.log('âœ… API: Technology rows fetched', { count: techRows?.length });
      const techNameToId = {};
      techRows.forEach(row => {
        techNameToId[row.name.toLowerCase()] = row.id;
      });

      technologyIds = technologies.map(name => techNameToId[name.toLowerCase()]).filter(Boolean);
      console.log('ðŸ”„ API: Technology IDs mapped', { count: technologyIds.length });

      // Insert project_technologies
      const techRowsToInsert = technologyIds.map(techId => ({
        project_id: project.id,
        technology_id: techId,
        is_highlighted: highlighted_technologies
          .map(str => str.toLowerCase())
          .includes(
            Object.keys(techNameToId).find(key => techNameToId[key] === techId)
          ),
      }));

      if (techRowsToInsert.length > 0) {
        console.log('ðŸ”„ API: Inserting project technologies', { count: techRowsToInsert.length });
        const { error: techError } = await supabase
          .from('project_technologies')
          .insert(techRowsToInsert);
        if (techError) {
          console.error('âŒ API: Error inserting technologies', techError);
          return res.status(500).json({ error: techError.message });
        }
        console.log('âœ… API: Project technologies inserted');
      }
    }

    // Insert project_tags
    if (tags.length > 0) {
      console.log('ðŸ”„ API: Fetching tag IDs', { tags });
      // Get tag IDs
      const { data: tagRows, error: tagFetchError } = await supabase
        .from('tags')
        .select('id, name')
        .in('name', tags);

      if (tagFetchError) {
        console.error('âŒ API: Error fetching tags', tagFetchError);
        return res.status(500).json({ error: tagFetchError.message });
      }

      console.log('âœ… API: Tag rows fetched', { count: tagRows?.length });
      const tagNameToId = {};
      tagRows.forEach(row => {
        tagNameToId[row.name.toLowerCase()] = row.id;
      });

      const tagIds = tags.map(name => tagNameToId[name.toLowerCase()]).filter(Boolean);
      console.log('ðŸ”„ API: Tag IDs mapped', { count: tagIds.length });

      const tagRowsToInsert = tagIds.map(tagId => ({
        project_id: project.id,
        tag_id: tagId,
        is_highlighted: highlighted_tags
          .map(str => str.toLowerCase())
          .includes(
            Object.keys(tagNameToId).find(key => tagNameToId[key] === tagId)
          )
      }));

      if (tagRowsToInsert.length > 0) {
        console.log('ðŸ”„ API: Inserting project tags', { count: tagRowsToInsert.length });
        const { error: tagError } = await supabase
          .from('project_tags')
          .insert(tagRowsToInsert);
        if (tagError) {
          console.error('âŒ API: Error inserting tags', tagError);
          return res.status(500).json({ error: tagError.message });
        }
        console.log('âœ… API: Project tags inserted');
      }
    }

    // --- CONTRIBUTION TYPES ---
    console.log('ðŸ”„ API: Processing contribution types');
    // Remove old project_contribution_type if updating
    if (isUpdate) {
      console.log('ðŸ”„ API: Removing old contribution types');
      const { error: contTypeDeleteError } = await supabase.from('project_contribution_type').delete().eq('project_id', project.id);
      if (contTypeDeleteError) console.error('âŒ API: Error deleting contribution types', contTypeDeleteError);
    }

    // Insert project_contribution_type
    if (contribution_types.length > 0) {
      console.log('ðŸ”„ API: Fetching contribution type IDs', { contribution_types });
      // Get contribution type IDs
      const { data: contTypeRows, error: contTypeFetchError } = await supabase
        .from('contribution_type')
        .select('id, name')
        .in('name', contribution_types);

      if (contTypeFetchError) {
        console.error('âŒ API: Error fetching contribution types', contTypeFetchError);
        return res.status(500).json({ error: contTypeFetchError.message });
      }

      console.log('âœ… API: Contribution type rows fetched', { count: contTypeRows?.length });
      const contTypeNameToId = {};
      contTypeRows.forEach(row => {
        contTypeNameToId[row.name.toLowerCase()] = row.id;
      });

      const contTypeIds = contribution_types.map(name => contTypeNameToId[name.toLowerCase()]).filter(Boolean);
      console.log('ðŸ”„ API: Contribution type IDs mapped', { count: contTypeIds.length });

      const contTypeRowsToInsert = contTypeIds.map(contTypeId => ({
        project_id: project.id,
        contribution_type_id: contTypeId
      }));

      if (contTypeRowsToInsert.length > 0) {
        console.log('ðŸ”„ API: Inserting contribution types', { count: contTypeRowsToInsert.length });
        const { error: contTypeError } = await supabase
          .from('project_contribution_type')
          .insert(contTypeRowsToInsert);
        if (contTypeError) {
          console.error('âŒ API: Error inserting contribution types', contTypeError);
          return res.status(500).json({ error: contTypeError.message });
        }
        console.log('âœ… API: Project contribution types inserted');
      }
    }

    // --- FETCH ALL ISSUES, PRs, AND COMMITS FROM GITHUB ---
    if (!isUpdate && github_link && owner && repoName) {
      try {
        // Fetch all issues (excluding PRs)
        const allIssues = await fetchAllFromGitHub(
          `https://api.github.com/repos/${owner}/${repoName}/issues?state=all`,
          githubToken
        );
        const issues = allIssues.filter(issue => !issue.pull_request);

        if (issues.length > 0) {
          const issueRows = issues.map(issue => ({
            project_id: project.id,
            issue_id: issue.id,
            title: issue.title?.substring(0, 1000) || null,
            body: issue.body?.substring(0, 10000) || null,
            state: issue.state?.substring(0, 100) || null,
            created_at: issue.created_at ? new Date(issue.created_at) : null,
            updated_at: issue.updated_at ? new Date(issue.updated_at) : null,
            number: issue.number,
            labels: Array.isArray(issue.labels) ? issue.labels.map(l => l.name) : [],
            url: issue.html_url?.substring(0, 500) || null,
          }));
          // Insert in batches of 1000 to avoid hitting Supabase limits
          for (let i = 0; i < issueRows.length; i += 1000) {
            await supabase.from('project_issues').upsert(issueRows.slice(i, i + 1000), { onConflict: ['project_id', 'issue_id'] });
          }
        }

        // Fetch all pull requests
        const prs = await fetchAllFromGitHub(
          `https://api.github.com/repos/${owner}/${repoName}/pulls?state=all`,
          githubToken
        );

        if (prs.length > 0) {
          const prRows = prs.map(pr => ({
            project_id: project.id,
            pr_id: pr.id,
            title: pr.title?.substring(0, 1000) || null,
            body: pr.body?.substring(0, 10000) || null,
            state: pr.state?.substring(0, 100) || null,
            created_at: pr.created_at ? new Date(pr.created_at) : null,
            updated_at: pr.updated_at ? new Date(pr.updated_at) : null,
            number: pr.number,
            labels: Array.isArray(pr.labels) ? pr.labels.map(l => l.name) : [],
            url: pr.html_url?.substring(0, 500) || null,
            merged: !!pr.merged_at,
          }));
          for (let i = 0; i < prRows.length; i += 1000) {
            await supabase.from('project_pull_requests').upsert(prRows.slice(i, i + 1000), { onConflict: ['project_id', 'pr_id'] });
          }
        }

        // Fetch all commits
        const commits = await fetchAllFromGitHub(
          `https://api.github.com/repos/${owner}/${repoName}/commits`,
          githubToken
        );

        if (commits.length > 0) {
          const commitRows = commits.map(commit => ({
            project_id: project.id,
            commit_id: commit.sha,
            message: commit.commit?.message?.substring(0, 1000) || null,
            author: commit.commit?.author?.name?.substring(0, 100) || null,
            timestamp: commit.commit?.author?.date ? new Date(commit.commit.author.date) : null,
            url: commit.html_url?.substring(0, 500) || null,
            branch: null,
          }));
          for (let i = 0; i < commitRows.length; i += 1000) {
            await supabase.from('project_commits').insert(commitRows.slice(i, i + 1000));
          }
        }

        console.log('âœ… API: Fetched and stored ALL issues, PRs, and commits from GitHub');
      } catch (err) {
        console.error('âŒ API: Error fetching GitHub data on project creation', err);
        // Optionally, you can return an error or continue
      }
    }

    console.log('âœ… API: Project process completed successfully', { projectId: project.id, isUpdate });
    return res.status(isUpdate ? 200 : 201).json({ projectId: project.id });
  } catch (error) {
    console.error('âŒ API: Unhandled error in project create/update', error);
    return res.status(500).json({ error: error.message || 'Internal server error' });
  }
}
